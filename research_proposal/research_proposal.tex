\documentclass[a4paper,11pt]{article}

\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}

\usepackage{hyperref}

\bibliographystyle{plain}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}

% add paragraph breaks
\setlength{\parskip}{0.5em}
\renewcommand{\baselinestretch}{1.0}
\setlength{\parindent}{0em}

\usepackage{amsmath}

\usepackage{pdflscape}

\usepackage{tabularx}
\usepackage[table]{xcolor}
\usepackage{multirow}

\begin{document}
    \section*{Space efficient pattern matching in theory and practice}

    \section*{The proposers}

    \subsection*{The University of Bristol}

    The Department of Computer Science at the University of Bristol has 9 professors, 19 lecturers and 44 research assistants across a total of 7 research groups. The central research group in this project is the Theory and Algorithms Group, which has 5 lecturers, 2 researchers and 2 PhD students. Funding within this group primarily comes from the EPSRC, under the Fundamentals of Computing EPSRC Research Topic Classification. The University of Bristol is also home to a three-phase high performance computing machine called Blue Crystal.

    \subsubsection*{Dr.\@ Dominic Moylett: Primary Investigator}

    Dominic is a Lecturer in the Theory and Algorithms Group, specialising in space efficient computation. He developed the first ever implementation of Breslauer and Galil's algorithm for sublinear space pattern matching, and implemented an earlier version of Clifford et al.'s algorithm for sublinear space dictionary matching. Prior to his Lectureship, he was a PhD student and Post-Doctoral Research Assistant at the University of Warwick under the supervision of Prof.\@ Graham Cormode, where he investigated the theory and practice of efficient, verifiable computation on large sets of data when delegated to a cloud service. His past publications on space efficient algorithms include two papers at the ACM Symposium on the Theory of Computation (STOC) and four at the Annual Symposium on Combinatorial Pattern Matching (CPM). He has collaborated on multiple occasions with Dr.\@ Rapha\"{e}l Clifford at Dr.\@ Benjamin Sach from the University of Bristol Theory and Algorithms Group.

    \subsubsection*{Dr.\@ Charles Anderson: Co-Investigator}

    Charles is a Lecturer in the Theory and Algorithms Group, specialising in the theoretical and empirical analysis of algorithms. He developed the first ever implementation of Bille et al.'s algorithm for constructing sparse suffix trees in small space. During his PhD and Post-Doctoral Research Fellowship under the supervision of Dr.\@ Benjamin Sach, he worked on practical evaluations even further, investigating the benefits of high performance computing, contributing to the Multiple Precision Integers and Rationals (MPIR)\footnote{\url{http://mpir.org/index.html}} library for parallel multiple-precision arithmetic, and releasing applications for problems ranging from bioinformatics to computer security which utilised new algorithms. He has three accepted papers at CPM and four at the IEEE International Conference on Data Engineering (ICDE). Since joining the University of Bristol, he has collaborated with Dr.\@ Dominic Moylett on several projects, focusing on the area of space efficient data processing.

    \newpage
    \section*{Space efficient pattern matching in theory and practice}
    \section*{Case for support}

    \section{Overview and motivation}

    Pattern matching is a wide collection of problems oriented around one simple question: ``Where does this pattern occur in this text?'' From this question a number of varients occur, including:

    \begin{itemize}
        \item \textbf{$k$-mismatch:} Where does this pattern occur in the text with up to $k$ characters different?
        \item \textbf{Pattern matching with wildcards:} Where does this pattern occur in the text if we ignore these characters?
        \item \textbf{Dictionary matching:} Where do any of these patterns occur in the text?
        \item \textbf{Parameterised matching:} Where does this pattern match the text if we relabel the pattern under some one-one mapping?
        \item \textbf{Distance matching:} How much does this text differ from the pattern?
    \end{itemize}

    The topic broadens out even further from here, leading to a variety of applications. Parameterised matching for example has seen a number of applications in checking for duplicated code \cite{Baker:1993:TPP:167088.167115} and plagiarism in software \cite{Pandey:plagiarism} by checking source files for where the same code is used but variables are simply renamed. Dictionary matching has seen applications in problems ranging from bioinformatics -- matching against whole databases of genomes \cite{15713233} -- to intrusion detection -- matching the contents of data packets against collections of attack patterns \cite{1354682}. Dictionary matching techniques are even used in Snort,\footnote{See \url{http://manual.snort.org/node16.html\#SECTION00313100000000000000}, under \texttt{config detection}} the ``most widely deployed intrusion prevention system in the world.''\footnote{\url{https://www.snort.org/\#blog_interlude}} $k$-mismatch solutions have also been used in bioinformatics for aligning sequences with a reference genome \cite{Tennakoon10062012}.

    But there is a problem here. For many of these applications, the size of the data is orders of magnitude greater than the original solutions were devised for. Take dictionary matching as an example, for which the applications mentioned above use an algorithm devised in 1975 by Aho and Corasick \cite{Aho:1975:ESM:360825.360855}. When Aho and Corasick first proposed this algorithm, they did not intend for it to be used to match databases of genomes or attack patterns. Instead, they used it to match at most two dozen keywords in 10MB of data from the titles of various academic papers. Even more pressing is that they explicitly state in their paper that for some applications the algorithm may be unappealing because of its space consumption.

    It might be interesting to ask at this point if this can't simply be resolved by improvements in hardware, following trends such as Moore's Law \cite{658762} and its variants. But there are a number of problems with this line of thinking. Firstly, even if we assume the space available on RAM will never stop increasing, the amount of data we want to process is still increasing faster than our capability to store it. As it was said by Lincoln Stein, ``at some time in the not too distant future it will cost less to sequence a base of DNA than to store it on a hard disk.'' \cite{20441614} And secondly, there are some cases where we do not want to keep adding RAM to our hardware as that will increase the physical space and power demand of these devices. Examples of this include performing intrusion detection on embedded systems such as routers.

    Because of this, space efficiency has become a significant concern. Since 2009 \cite{5438620}, a number of solutions have been discovered to prove that it is possible to solve a number of problems not only in less space than it takes to store the text, but less space than it takes to even store the pattern. The aims of our work detailed within this research proposal is to develop on these results further, focusing on two areas in particular:

    \begin{itemize}
        \item In the theory domain, we will improve upon current time and space bounds for the $k$-mismatch, parameterised matching and dictionary matching problems. We will also provide the first sublinear space solution for pattern matching with both multiple texts and multiple patterns.
        \item In the applied domain, we will develop implementations of both algorithms developed following the theoretical work in this research proposal and previous algorithms which to our knowledge have never seen prior implementation. We will test these algorithms, compare their performance to benchmark solutions, and improve the real world performance by finding and optimising practical bottlenecks. The test benches will be publicly accessible and allow anyone to contribute their own solutions. Finally, we will release these implementations as practical tools to the open source community under the GNU General Public License (GPL).
    \end{itemize}

    \section{Background}

    It is straightforward to find a way of not needing to store the whole text on a machine. A lot of pattern matching algorithms such as Knuth-Morris-Pratt \cite{kmp} operate by only reading the text once and processing each character individually. Thus we only need to store a window of the text in memory during processing, as opposed to the whole text, and update that window as we read the next character of the text. This is frequently known as \textit{streaming} the input, and is more formally called the time series model \cite{TCS-002}.

    But pattern matching in less space than it takes to store the pattern is significantly more difficult. After all, how can we check if a pattern has occurred if we don't have enough space to know what the pattern is? Clifford et al.\@ \cite{clifford:black-box} proved that this intuition held for many problems; as long as we did not want any chance of errors, it was impossible to perform pattern matching in sublinear space relative to the pattern.

    This changed however in 2009 in a paper by Porat and Porat \cite{5438620}. They showed that if we allowed both false positive and false negative results to occur with some negligible probability, we could achieve a solution for the classic pattern matching problem in logarithmic time per character and sublinear space. This was the first ever solution to, as the authors themselves put it, break ``the $O(m)$ barrier that held for this problem for a long time.'' Breslauer and Galil \cite{Breslauer:2014:RSS:2660854.2635814} improved on this work even further, by reducing the time complexity of the algorithm to constant time per character and only producing false positives.

    Subsequent work has been focused around two areas. The first, largely investigated by Clifford et al.\@ \cite{DBLP:journals/corr/abs-1106-4412}, provided a number of key insights into the space lower bounds of these problems. In particular, they proved that the classic pattern matching problem requires logarithmic words of space, and many other problems including distance matching and pattern matching with wildcards require linear space.

    The second direction was to see what other problems could be solved in this area. Alongside their solution for classic pattern matching, Porat and Porat \cite{5438620} provided a solution to the $k$-mismatch problem in sublinear time and space. The next major breakthrough was in 2013, when Jalsenius, Porat and Sach \cite{JPS:2013} provided a solution to the parameterised matching problem in sublinear space, and introduced a space lower bound as large as the alphabet of the text and pattern. The most recent accomplishment in this direction has been by Clifford et al.\@ \cite{2015arXiv150406242C}, which provided a solution to the dictionary matching problem in log-log time per character and sublinear space to storing every pattern. This will be the theoretical direction we focus on in this project.

    In the practical world, work has been a lot less well-known. There are little to no currently published papers on implementing these algorithms, and thus we know almost nothing about how well these algorithms will perform in practice. This has been a common problem throughout theoretical computer science, and has thus resulted in a number of conferences based around applied and experimental work, such as the Conference on Algorithms and Discrete Applied Mathematics (CALDAM).

    To offer contributions to the practical domain, we will implement classic solutions to pattern matching algorithms as benchmarks and provide implementations of these more recent solutions. We will complement these implementations with a number of test benches for the problems, similar to the experimental setup of the Pizza\&Chili Corpus\footnote{\url{http://pizzachili.dcc.uchile.cl/index.html}} for text indexing. To ensure our work is reproduceable, we will host online access to these experimental setups and allow visitors the ability to contribute their own solutions to the pattern matching problems. Using these test benches will also give us key insights into the practical bottlenecks of these algorithms, and give us ideas as to how we can reduce the size of the constants that result from this work. Finally, we will release these solutions publicly under the GPL, and propose integration of these solutions into projects such as Snort.

    \section{Objectives and deliverables}

    Our aims for this project are to investigate improvements to the current theoretical achievements, propose new solutions to open problems, and develop practical implementations of these algorithms to release to the public. Specifically, our objectives are:

    \begin{enumerate}
        \item To work on improvements to current bounds for a number of problems, such as time bounds for dictionary matching, and time and space bounds for $k$-mismatch.
        \item To propose solutions to open problems, such as matching multiple patterns against multiple texts, for which the only sublinear space solution involves running multiple independent instances of the Clifford et al.\@ algorithm for dictionary matching.
        \item To develop implementations of algorithms from both this project and other work, and develop test benches in order to profile and optimise bottlenecks when running these algorithms on real data.
        \item To release these implementations as libraries under the GPL.
    \end{enumerate}

    \subsection{Deliverables}

    \begin{enumerate}
        \item New algorithms to improve time and space bounds for current problems.
        \item Publicly accessible test benches for empirical analysis of solutions to different pattern matching problems.
        \item Release of implementations as libraries under the GPL and contributions to open source projects such as Snort.
    \end{enumerate}

    \section{Programme and methodology}

    \subsection*{Work package 1 (WP1): Advances in theoretical work}

    Research leader: Dominic Moylett

    Principle research objective:
    \begin{quote}
        To reduce the current gaps between upper and lower bounds for sublinear space pattern matching algorithms through improving the best known theoretical algorithms.
    \end{quote}

    Principle deliverables:
    \begin{enumerate}
        \item Improved algorithms towards problems such as $k$-mismatch and dictionary matching.
        \item Sublinear space algorithms for new problems such as multiple texts and multiple patterns.
    \end{enumerate}

    This work package is to address objectives one and two from our list of main objectives, as well as deliverable one. The criteria for success will be to what extent we manage to improve the worst case performance for these problems.

    The post doctoral research assistant (PDRA) will be involved in this work package, due to the theoretical challenges involved in devising new solutions to algorithms. We will also collaborate with other academics, including the rest of the Theory and Algorithms Group at the University of Bristol.

    \subsection*{Work package 2 (WP2): Implementation of theoretical solutions}

    Research leader: Charles Anderson

    Principle research objective:
    \begin{quote}
        To implement a selection of algorithms for various pattern matching problems, measure their performance on test benches when applied to real data and devise a number of practical optimisations based on bottlenecks discovered.
    \end{quote}

    Principle deliverables:
    \begin{enumerate}
        \item A number of implementations for various stream-based pattern matching algorithms, optimised based on practical bottlenecks found during profiling.
        \item A collection of test benches for measuring various performance qualities of these implementations, including but not limited to working space during processing, preprocessing time, (amortised and/or worst case) run time per character, and rate of false positives/false negatives.
    \end{enumerate}

    There are two long term goals in particular for this work package. Firstly, we want others to have the ability to reproduce our experimental results. And secondly, we want to encourage further developments in this area after our project is complete.

    With these goals in mind, the test benches developed during the work package are to be made publicly available online. They will be hosted on a cloud service provider and set up such that anyone can upload an implementation to be measured on a test bench, as long as the implementation's source code integrates with the framework. If every performance test is successfully completed, the uploaders can decide whether to publish their source code and performance on the website, based on the results from testing.

    The majority of this work package is to be completed by a PhD student, under the supervision of the co-investigator for this period of the project. Note that we have not mentioned any specific algorithms for the student to implement. Guidance will be offered, but the emphasis will be on \textit{them} choosing which algorithms they implement. The only caveat is that in later years of this work package, we will encourage them to implement some of the solutions resulting from WP1.

    \subsection*{Work package 3 (WP3): Release of open source tools}

    Research leader: Dominic Moylett

    Principle research objective:
    \begin{quote}
        To release the implementations from WP2 under the GPL and provide them as contributions into other open source projects.
    \end{quote}

    Principle deliverables:
    \begin{enumerate}
        \item Open source releases of the implementations from WP2 as libraries.
        \item Accepted contributions into or forks from established open source projects with the aforementioned libraries integrated into the applications.
    \end{enumerate}

    The reason for distinguishing between this work package and WP2 is because of the different groups targeted for each package. WP2 is targeted at the academic community, with emphasis on experimentation. This package is to cater for the industrial community, to show how these implementations can be used in the real world as opposed to merely within an experimental setting. Despite this difference in audience, there is still a connection between this work and WP2, and will therefore be primarily carried out by the PhD student.

    The overall aim with this work package is to understand how useful the algorithms are when applied to real applications. Unlike WP1 and WP2, this cannot be easily measured, and thus determining our success is more challenging here. So for this work package, we will gather feedback from industrial contacts to decide the extent to which our aims have been achieved.

    \section{Academic impact}

    Work packages WP1 and WP2 target distinct academic beneficiaries: The beneficiaries of WP1 are the algorithms and theory of computing community, whereas academic beneficiaries of WP2 are people within applied and experimental communities. The research proposed will provide both new insight into the theoretical community, and open source tools and experiment services for applied research and real-life applications. Academic work from WP1 and WP2 will be disseminated through publications and conferences, and the test benches themselves will be freely available online and supported with workshops featuring demonstrations and advice on how to contribute.
    \bibliography{research_proposal}

    \newpage
    \section{Impact statement}

    As stated in the Academic impact section, WP1 and WP2 will target academic beneficiaries by advancing scientific knowledge and improving techniques. WP3 on the other hand will have an impact primarily in the industrial sectors. Our implementations of these space efficient pattern matching algorithms will be released as open source libraries for anyone to freely use and contribute to, thus allowing for open innovation and improved performance for current products and procedures. We will also show how people can integrate our libraries into their projects by making our own contributions to already existing open source projects which rely on pattern matching algorithms. Already there is discussion in the Theory and Algorithms group at the University of Bristol to contribute an implementation of the Clifford et al.\@ algorithm for dictionary matching to Snort.

    In order for this work to be beneficial, we need to address two challenges. Firstly, we need to know what other properties do the industrial community care about and what our research can do to best address their needs during execution. And secondly, we need to know how are we going to best share this knowledge at the initial moment of release. We will face these challenges by hosting three workshops for the project with academics and industrial people from groups such as the International Society for Computational Biology (ISCB) and the European Data Science Academy (EDSA) to represent the bioinformatics and data science communities respectively:

    \begin{itemize}
        \item The first, to be held at the start of the project, will focus on tackling the first challenge. In it, we will establish conversations with these groups to understand their needs and to how this research can benefit them.
        \item The second, to be held 2.5 years in, will provide the results of our empirical analysis to both academics and industrial contacts. The opinions of the attendees will be used to gauge continued interest in our implementations before attempting to integrate the libraries into open source projects. During this workshop, we will also demonstrate to others how they can contribute to the knowledge base themselves by submitting their own pattern matching solutions to be analysed and compared.
        \item The final, to be held at the end of the project, will focus around demonstrating our open source libraries and showing how people can integrate them into their own products and provide their own contributions to the libraries. Discussions at this workshop will be used to assist in judging the success of WP3.
    \end{itemize}

    Alongside the release and integration of our libraries into open source projects, we provide an impact within the wider R\&D community through the release and public access of our test benches. Often pattern matching algorithms are not useful in real world applications as the academics who devise them only focus on the worst-case scenario once the data becomes sufficiently large. We hope to alleviate this by providing services that can test an individual's implementations automatically and uniformly. There are few services which currently offer this utility for pattern matching; one example for compressed text indexing is the Pizza\&Chili Corpus.

    If our results from WP2 and WP3 are viewed positively, then we would expect to see a growth in the development and release of libraries for practical pattern matching. More pattern matching libraries will mean more choices to external disciplines and industry, who can pick the option that best fits their needs. Even better, the encouragement of open source libraries can result in members of industry contributing changes back that made the libraries more suitable for their needs. In the long term, this mutual feedback and contributions to open source might be the greatest impact provided by this work.

    \newpage
    \section{Budget}

    \begin{center}
        \begin{tabular}{|l|l|}
            \hline
            Item & Cost for 3.5 years (\textsterling) \\\hline
            PI & 350,000 \\\hline
            CI & 87,500 \\\hline
            PDRA & 350,000 \\\hline
            PhD student & 100,000 \\\hline
            Equipment & 3,000 \\\hline
            Cloud computing resources & 27,452 \\\hline
            International travel costs & 28,000 \\\hline
            National travel costs & 10,500 \\\hline
            Workshops & 1,800 \\\hline
            \textbf{Total cost} & 958,252 \\\hline
        \end{tabular}
    \end{center}

    \section{Justification for resources}

    \subsection{Staff}

    The most significant costs are the time of the PI, PDRA and PhD student, who will work close to full time on this project. As the CI's work is focused around the supervision of the PhD student -- particularly during the execution of WP2 -- they will contribute 25\% of their time.

    \subsection{Resources}

    \textsterling1,000 is allocated to the PhD student for the set up of a high-end PC. An additional \textsterling1,000 is for any specialist software to aid the applied work, such as software licenses for debuggers and profilers, and an extra \textsterling1,000 for any required maintenance of the computing resources over the length of the project.

    For cloud computing resources, we have budgeted for two Amazon EC2 c3.8xlarge instances in their Ireland data centre. These were selected due to their computation performance and storage size, which will be useful given the size of our data for testing. Two instances will give us 64 virtual CPUs, in order to help increase the number of tests we can run simultaneously. These will be bought under three-year term all upfront payments, which are currently valued at \$21,669, or \textsterling13,726 each.

    \subsection{Travel}

    Budget has been allocated for each member of the team to travel to one relevant conference a year, such as the ACM-SIAM Symposium on Discrete Algorithms (SODA) for WP1, and CALDAM for WP2 and WP3. Each conference has been budgeted at \textsterling2,000: \textsterling900 for air travel, \textsterling700 for accommodation and \textsterling400 for registration.

    Alongside these costs, \textsterling750 per year has been allocated to each member for additional travelling. This is to encourage collaboration with other academics and industrial advisers across the UK.

    \subsection{Workshops}

    Three workshops will be arranged as stated in order to promote our results to the wider community. To cover the cost of catering, \textsterling600 has been budgeted for each workshop.

    \newpage
    \begin{landscape}
    \section{Workplan}

    \begin{tabularx}{\linewidth}{|lX|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
        \multirow{2}{*}{WP} & \multirow{2}{*}{Task} & 2015 & 2015 & 2016 & 2016 & 2016 & 2016 & 2017 & 2017 & 2017 & 2017 & 2018 & 2018 & 2018 & 2018 \\
        & & Q3 & Q4 & Q1 & Q2 & Q3 & Q4 & Q1 & Q2 & Q3 & Q4 & Q1 & Q2 & Q3 & Q4 \\\hline
        D1.1 & Establish academic connections & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & & & & & & & & \\\hline
        D1.1 & Improve current algorithms & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & \\\hline
        D1.2 & Investigate open problems & & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & & & \\\hline
        D1.2 & Develop new solutions & & & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} \\\hline
        D2.1 & Establish academic connections & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & & & & & & & & \\\hline
        D2.1 & Implement algorithms & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & & \\\hline
        D2.2 & Develop experimental setups & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & \\\hline
        D3.1 & Establish industrial connections & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & \\\hline
        D3.1 & Release implementations as libraries under the GPL & & & & & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & \\\hline
        D3.1 & Integrate libraries into open source projects & & & & & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \\\hline
    \end{tabularx}

    \subsection*{Notes for the workplan}

    Deliverables are denoted D$x.y$, where $x$ is the work package and $y$ is the principle deliverable for that work package.

    We expect to have hired both the PDRA and the PhD student within the first six months of this project, and that both will have commenced work in 2016 Q1. The work of hiring these two is part of establishing academic connections, during which time we will also be seeking other academics to connect with. With both academic and industrial connections, we expect further networking and communication to occur after the periods marked in the workplan for establishing connections, due to the continuous nature of this task. We also expect further work in WP2 for continued maintenance of the test benches. These tasks have been omitted from the workplan.

    2018 Q4 has no work on WP2 and WP3 as the PhD student will use this time to write up their results in a thesis. Work on WP1 will continue during this period.

    For key dates, we will have at least three papers accepted by 2016 Q4: Two for WP1, one for WP2. We will also have at least one more accepted paper for WP2 by 2017 Q4, one for WP3 by 2018 Q3 at a conference such as the Free Software and Open Source Symposium (FSOSS), and at least two more for WP1 by 2018 Q4. Three workshops will be arranged: One during 2015 Q4 to help establish academic and industrial relations, one during 2017 Q4 for demonstrating the services from WP2, and one in 2018 Q4 for demonstrating the tools from WP3.

    \end{landscape}

\end{document}
