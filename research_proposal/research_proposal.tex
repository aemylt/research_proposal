\documentclass[a4paper,11pt]{article}

\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}

\usepackage{hyperref}

\bibliographystyle{plain}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}

% add paragraph breaks
\setlength{\parskip}{0.5em}
\renewcommand{\baselinestretch}{1.0}
\setlength{\parindent}{0em}

\usepackage{amsmath}

\usepackage{pdflscape}

\usepackage{tabularx}
\usepackage[table]{xcolor}
\usepackage{multirow}

\DeclareMathOperator\polylog{polylog}

\begin{document}
    \section*{The Theory and Practice of Sublinear Space Pattern Matching}

    \section*{The proposers}

    \subsection*{The University of Bristol}

    The Department of Computer Science at the University of Bristol has 9 professors, 19 lecturers and 44 research assistants across a total of 7 research groups. The central research group in this project is the Theory and Algorithms Group, which has 5 lecturers, 2 researchers and 2 PhD students. Funding primarily comes from the EPSRC, under the Fundamentals of Computing EPSRC Research Topic Classification. The University of Bristol is also home to a three-phase high performance computing machine called Blue Crystal.

    \subsubsection*{Dominic Moylett: Primary Investigator}

    \subsubsection*{Charles Anderson: Co-Investigator}

    \newpage
    \section*{The Theory and Practice of Sublinear Space Pattern Matching}
    \section*{Case for support}

    \section{Overview and motivation}

    Pattern matching is a wide collection of problems oriented around one simple question: ``Where does this pattern occur in this text?'' From this question a number of varients occurr, including:

    \begin{itemize}
        \item \textbf{$k$-mismatch:} Where does this pattern occur in the text with up to $k$ characters different?
        \item \textbf{Pattern matching with wildcards:} Where does this pattern occur in the text if we ignore these characters?
        \item \textbf{Dictionary matching:} Where do any of these patterns occur in the text?
        \item \textbf{Parameterised matching:} Where does this pattern match the text if we relabel the pattern under some one-one mapping?
        \item \textbf{Distance matching:} How much does this text differ from the pattern?
    \end{itemize}

    From here, the topic broadens out even further, giving way to a wide variety of applications. Parameterised matching for example has seen a number of applications in checking for duplicated code \cite{Baker:1993:TPP:167088.167115} and plagiarism in software \cite{Pandey:plagiarism}, checking source files for where the same code is used with merely a few variables difference. Dictionary matching has seen applications in problems ranging from bioinformatics -- matching against whole databases of genomes \cite{15713233} -- to intrusion detection -- matching the contents of data packets against collections of attack patterns \cite{1354682}.\footnote{Also see \url{http://manual.snort.org/node16.html\#SECTION00313100000000000000}, under \texttt{config detection}} $k$-mismatch solutions have also been used in bioinformatics for aligning sequences with a reference genome \cite{Tennakoon10062012}.

    But there is a problem here. For many of these applications, the size of the data is orders of magnitude greater than the original solutions were devised for. Take dictionary matching as an example, for which the applications mentioned above use an algorithm devised in 1975 by Aho and Corasick \cite{Aho:1975:ESM:360825.360855}. When Aho and Corasick first proposed this algorithm, they did not intend for it to be used to match databases of genomes or attack patterns. Instead, they used it to match two dozen keywords in the titles of various academic papers. Even more pressing is that they explicitly state in their paper that for some applications the algorithm may be unappealing because of its space consumption.

    It might be interesting to ask at this point if this can't simply be resolved by improvements in hardware. But there are a number of problems with this line of thinking. Firstly, even if we assume the space available on RAM will never stop increasing and that we can always use this space fully, the amount of data we want to process is still increasing faster than our capability to store it. As it was said by Lincoln Stein, ``at some time in the not too distant future it will cost less to sequence a base of DNA than to store it on a hard disk.'' \cite{20441614} And secondly, there are some cases where we do not want to keep adding RAM to our hardware as that will most likely increase the physical space of these devices. Examples of this include pattern matching on our phone, or on embedded systems such as intrusion detection on routers.

    Since 2009 \cite{5438620}, a number of solutions have been discovered to prove that it is possible to solve a number of problems not only in less space than it takes to store the text, but less space than it takes to even store the pattern. Following this, the aims of our work following this research proposal is to develop on these results further, focusing on two areas in particular:

    \begin{itemize}
        \item In the theory domain, we aim to improve upon current time and space bounds for the $k$-mismatch, parameterised matching and dictionary matching problems. We also seek to provide the first sublinear space solution for pattern matching with both multiple texts and multiple patterns.
        \item In the applied domain, we aim to provide implementations of both algorithms developed following the theoretical work in this research proposal and previous algorithms which to our knowledge have never seen prior implementation. We seek to test these algorithms and compare their performance to benchmark solutions in real applications, and improve the real world performance by finding and optimising practical bottlenecks. Finally, we aim to release these implementations as practical tools to the Open-Source community under the GNU General Public License (GPL).
    \end{itemize}

    \section{Background}

    It is straightforward to find a way of not needing to store the whole text on a machine. A lot of pattern matching algorithms such as Knuth-Morris-Pratt \cite{kmp} function by only reading one character of the text at a time. Thus we only need to store a window of the text in memory during processing, as opposed to the whole text, and update that window as we read the next character of the text. This is frequently known as \textit{streaming} the input, and is more formally called the time series model \cite{TCS-002}.

    But pattern matching in less space than it takes to store the pattern is significantly more difficult. Intuitively, this makes sense; how can we check if a pattern has occurred if we don't have enough space to know what the pattern is? Clifford et al.\@ \cite{clifford:black-box} proved that this intuition held for many problems; as long as we did not want any chance of errors, it was impossible to perform pattern matching in sublinear space relative to the pattern.

    But in 2009, Porat and Porat \cite{5438620} proved that the problem was in not allowing for errors. If we allowed a chance of both false positive and false negative results with some negligible probability of error, we could achieve a solution for the classic pattern matching problem in logarithmic time per character and sublinear space. This was the first ever solution to, as the authors themselves put it, break ``the $O(m)$ barrier that held for this problem for a long time.'' Breslauer and Galil \cite{Breslauer:2014:RSS:2660854.2635814} improved on this work even further, reducing the time complexity of the algorithm to constant time per character.

    Subsequent work has been focused around two areas. The first, largely investigated by Clifford et al.\@ \cite{DBLP:journals/corr/abs-1106-4412}, provided a number of key insights into the space lower bounds of these problems. In particular, they proved that the classic pattern matching problem requires logarithmic words of space, and many other problems including distance matching and pattern matching with wildcards as mentioned above require at least linear space.

    The second direction was to see what other problems could be solved in this area. Alongside their solution for classic pattern matching, Porat and Porat \cite{5438620} provided a solution to the $k$-mismatch problem in sublinear time and space. The next major breakthrough was in 2013, when Jalsenius, Porat and Sach \cite{JPS:2013} provided a solution to the parameterised matching problem in sublinear space, and introduced a space lower bound as large as the alphabet of the text and pattern. The most recent accomplishment in this direction has been by Clifford et al.\@ \cite{2015arXiv150406242C}, which provided a solution to the dictionary matching problem in log-log time per character and sublinear space to storing every pattern.

    For our theoretical contributions, we will aim to provide results in both directions. We will investigate the gaps in time complexity between the sublinear space solutions and the best-known results. Under dictionary matching for example, the best known time complexity is constant time per character by using Aho-Corasick, while Clifford et al.'s sublinear space solution currently does not.

    In the practical world, work has been a lot less well-known. There are little to no currently published papers on implementing these algorithms, and thus we know almost nothing about how well these algorithms will perform in practice. This has been a common problem throughout theoretical computer science, and has thus resulted in a number of conferences based around applied and experimental work, such as Conference on Algorithms and Discrete Applied Mathematics (CALDAM)\footnote{\url{http://caldam.cse.iitk.ac.in/}} and the International Conference on Applied Algorithms (ICAA)\footnote{\url{https://sites.google.com/site/icaa2014/}}.

    To offer contributions to the practical domain, we will implement classic solutions to pattern matching algorithms as benchmarks and provide implementations of these more recent solutions. We will complement these implementations with a number of test benches for the problems, similar to the experimental setup of the Pizza\&Chili Corpus\footnote{\url{http://pizzachili.dcc.uchile.cl/index.html}} for text indexing. To ensure our work is reproduceable, we will host online access to these experimental setups and allow visitors the ability to contribute their own solutions to the pattern matching problems. Using these test benches will also give us key insights into the practical bottlenecks of these algorithms, and give us ideas as to how we can reduce the size of the constants that result from this work. Finally, we will release these solutions publicly under the GPL, and propose integration of these solutions into projects such as Snort.

    \section{Objectives and deliverables}

    Our aims for this project are to investigate improvements to the current theoretical achievements stated above, propose new solutions to currently open problems, and develop practical implementations of these algorithms to release to the public. Specifically, our objectives are:

    \begin{enumerate}
        \item To work on improvements to current bounds for a number of problems, including time bounds for dictionary matching, space bounds for parameterised matching, and time and space bounds for $k$-mismatch.
        \item To propose solutions to open problems. In particular, the only currently known sublinear space solution for the problem of matching multiple patterns against multiple texts involves running multiple independent instances of the Clifford et al.\@ algorithm for dictionary matching.
        \item To develop implementations of algorithms from both this project and other work, and develop test benches in order to profile and optimise bottlenecks when running these algorithms on real data.
        \item To release these implementations to the open-source community under the GPL.
    \end{enumerate}

    \subsection{Deliverables}

    \begin{enumerate}
        \item New algorithms to improve time and space bounds for current problems.
        \item Publicly accessible test benches for analysis of various streaming solutions to different pattern matching problems.
        \item Release of source code as libraries under the GPL, and proposals for integration into other open-source projects such as the Snort intrusion prevention system.
    \end{enumerate}

    \section{Work programme and methodology}

    \subsection*{Work package 1 (WP1): Advances in theoretical work}

    Research leader: Dominic Moylett

    Principle research objective:
    \begin{quote}
        To reduce the current gaps between upper and lower bounds for sublinear space pattern matching algorithms through improving the best known theoretical algorithms.
    \end{quote}

    Principle deliverables:
    \begin{enumerate}
        \item Improved algorithms towards problems such as $k$-mismatch and dictionary matching.
        \item Sublinear space algorithms for new problems such as multiple texts and multiple patterns.
    \end{enumerate}

    This work package is to address objectives one and two from our list of main objectives, as well as deliverable one. The main criteria for success with this work package will be a reduction in the gap between upper and lower bounds for these problems, as well as new algorithms to be utilised in WP2 and WP3.

    The post doctoral research assistant (PDRA) will be involved in this work package, due to the theoretical challenges involved in devising new solutions to algorithms.

    \subsection*{Work package 2 (WP2): Implementation of theoretical work}

    Research leader: Charles Anderson

    Principle research objective:
    \begin{quote}
        To implement a selection of algorithms for various pattern matching problems, measure their performance on test benches when applied to real data and devise a number of practical optimisations based on bottlenecks discovered.
    \end{quote}

    Principle deliverables:
    \begin{enumerate}
        \item A number of implementations for various stream-based pattern matching algorithms, optimised based on bottlenecks found during profiling.
        \item A collection of test benches for measuring various performance qualities of these implementations, including but not limited to: working space during processing, preprocessing time, (amortised and/or worst case) run time per character, and rate of false positives/false negatives.
    \end{enumerate}

    There are two broad aims in particular we want from this work package. Firstly, we want others to have the ability to reproduce our experimental results. And secondly, we want to encourage further developments in this area after our project is complete.

    With this in mind, these test benches are to be made, publicly available online. They will be hosted on a cloud service provider and set up such that anyone can upload an implementation to be measured on a test bench, as long as the implementation's source code integrates with the existing code and all tests terminate successfully. After all tests are complete, the uploaders can select whether to publish their source code and performance alongside those already published.

    The majority of this work package is to be completed by a PhD student, under the supervision of the co-investigator for this period of the project. Note that we have not mentioned any specific algorithms for the student to implement. Guidance will be offered, but the emphasis will be on \textit{them} choosing which algorithms they implement. The only caveat is that in later years of the project, we will recommend that they implement some of the algorithms from the work of WP1.

    \subsection*{Work package 3 (WP3): Release of open-source tools}

    Research leader: Dominic Moylett

    Principle research objective:
    \begin{quote}
        To release the implementations from WP2 under the GPL and provide them as contributions into other open-source projects.
    \end{quote}

    Principle deliverables:
    \begin{enumerate}
        \item Open-source releases of the implementations from the previous work package.
        \item Branches or forks in established open-source projects with implementations from WP2 integrated into the applications.
    \end{enumerate}

    The reason for distinguishing between this work package and WP2 is because of the different group targeted for each package. WP2 is aimed at the academic community, with emphasis on experimentation. This package is to cater for the industrial community, to show how these implementations can be used in the real world as opposed to merely within an experimental setting. Despite this difference in audience, there is still a connection between this work and WP2, and will therefore be primarily carried out by the PhD student.

    The overall aim with this work package is to understand how useful the algorithms are when applied to real applications. Unlike WP1 and WP2, this cannot be easily measured, and thus determining our success is more challenging here. With this in mind, we aim to utilise industrial contacts for feedback about the algorithms, and rely on the judging of the EPSRC panel to decide the extent of which this work package has been successfully completed.

    \section{Academic Impact}

    Work packages WP1 and WP2 target distinct academic beneficiaries: The beneficiaries of WP1 are the algorithms and theory of computing community, whereas academic beneficiaries of WP2 are people within applied and experimental communities. The research proposed will provide both new insight into the theoretical community, and open-source tools and experiment services for applied research and real-life applications. Academic work from WP1 and WP2 will be disseminated through publications and conferences, and the services themselves will be freely available online and supported with workshops.
    \bibliography{research_proposal}

    \newpage
    \section{Budget}

    \begin{center}
        \begin{tabular}{|l|l|}
            \hline
            Item & Cost for 3.5 years (\textsterling) \\\hline
            PI & 350,000 \\\hline
            CI & 87,500 \\\hline
            PDRA & 350,000 \\\hline
            PhD student & 100,000 \\\hline
            Equipment & 3,000 \\\hline
            Cloud computing resources & 27,452 \\\hline
            International travel costs & 28,000 \\\hline
            National travel costs & 10,500 \\\hline
            Workshops & 1,800 \\\hline
            \textbf{Total cost} & 958,252 \\\hline
        \end{tabular}
    \end{center}

    \section{Justification for resources}

    \subsection{Staff}

    The most significant costs are the time of the PI, PDRA and PhD student, who will work close to full time on this project. As the CI's work is focused around the supervision of the PhD student during WP2, they will only contribute 25\% of their time.

    \subsection{Resources}

    \textsterling1,000 is allocated to the PhD student for the set up of a high-end PC. An additional \textsterling1,000 is for any specialist software to aid the applied work, such as software licenses for debuggers and profilers, and \textsterling1,000 for any required maintenance of the computing resources over the length of the project.

    For cloud computing resources, we have budgeted for two Amazon EC2 c3.8xlarge instances in their Ireland data centre. These were selected due to their computation performance, which will be useful given the size of our data. Two instances will give us 64 virtual CPUs, in order to help increase the number of tests we can run simultaneously. These will be bought under a three-year term all upfront payment, which is currently valued as \$21,669, or \textsterling13,726.

    \subsection{Travel}

    Budget has been allocated for each member of the team to travel to one relevant conference a year, such as the ACM-SIAM Symposium on Discrete Algorithms (SODA) for WP1, and CALDAM for WP2 and WP3. Each conference has been budgeted at \textsterling2,000: \textsterling900 for air travel, \textsterling700 for accommodation and \textsterling400 for registration.

    Alongside these costs, \textsterling750 per year has been allocated to each member for additional travelling. This is to assist collaboration with other academics and industrial advisers across the UK.

    \subsection{Workshops}

    Three workshops will be arranged as stated at the end of notes for the workplan. To cover the cost of catering for these events, \textsterling600 has been allocated in the budget.

    \newpage
    \section{Impact statement}

    \newpage
    \begin{landscape}
    \section{Workplan}

    \begin{tabularx}{\linewidth}{|lX|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
        \multirow{2}{*}{WP} & \multirow{2}{*}{Task} & 2015 & 2015 & 2016 & 2016 & 2016 & 2016 & 2017 & 2017 & 2017 & 2017 & 2018 & 2018 & 2018 & 2018 \\
        & & Q3 & Q4 & Q1 & Q2 & Q3 & Q4 & Q1 & Q2 & Q3 & Q4 & Q1 & Q2 & Q3 & Q4 \\\hline
        D1.1 & Establish academic connections & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & & & & & & & & \\\hline
        D1.1 & Improve current algorithms & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & \\\hline
        D1.2 & Investigate open problems & & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & & & \\\hline
        D1.2 & Develop new solutions & & & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} \\\hline
        D2.1 & Establish academic connections & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & & & & & & & & \\\hline
        D2.1 & Implement algorithms & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & & \\\hline
        D2.2 & Develop experimental setups & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & \\\hline
        D3.1 & Establish industrial connections & & & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & & & & & \\\hline
        D3.1 & Adjust implementations for open-source projects & & & & & & & & & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \cellcolor[gray]{0.5} & \\\hline
    \end{tabularx}

    \subsection*{Notes for the workplan}

    Deliverables are denoted D$x.y$, where $x$ is the work package and $y$ is the principle deliverable for that work package.

    We expect to have hired both the PDRA and the PhD student within the first six months of this project, and that both will have commenced work in 2016 Q1. The work of hiring these two is part of establishing academic connections, during which time we will also be seeking other academics to connect with.

    With both academic and industrial connections, we expect further networking and communication to occur after the periods marked in the workplan for establishing connections, due to the continuous nature of this task. This has been omitted from the above diagram.

    2018 Q4 has no work on WP2 and WP3 due to the expectation of the PhD student to use this time to write up their results in a thesis. Work on WP1 will continue as before.

    For key release dates, we expect at least three accepted papers by the end of 2016 Q4: two for WP1, one for WP2. We also expect at least one more paper for WP2 by the end of 2017 Q4, one for WP3 by the end of 2018 Q3, and at least two for WP1 by the end of 2018 Q4. Three workshops will be arranged: One at the start of 2015 Q3 to help establish academic and industrial relations, one primarily for demonstrating the services from WP2 at the end of 2017 Q4, and one at the end of 2018 Q4 primarily for demonstrating the tools from WP3.

    \end{landscape}

\end{document}
