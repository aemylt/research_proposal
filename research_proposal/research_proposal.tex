\documentclass[a4paper,11pt]{article}

\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}

\usepackage{hyperref}

\bibliographystyle{plain}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}

% add paragraph breaks
\setlength{\parskip}{0.5em}
\renewcommand{\baselinestretch}{1.0}
\setlength{\parindent}{0em}

\usepackage{amsmath}

\DeclareMathOperator\polylog{polylog}

\begin{document}
    \section*{The Theory and Practice of Sublinear Space Pattern Matching}

    \section*{The proposers}

    \subsection*{Dominic Moylett: Primary Investigator}

    \subsection*{Charles Anderson: Co-Investigator}

    \newpage
    \section*{The Theory and Practice of Sublinear Space Pattern Matching}
    \section*{Case for support}

    \section{Overview and motivation}

    Pattern matching is a wide collection of problems oriented around one simple question: ``Where does this pattern occur in this text?'' From this question a number of varients occurr, including:

    \begin{itemize}
        \item \textbf{$k$-mismatch:} Where does this pattern occur in the text with up to $k$ characters different?
        \item \textbf{Pattern matching with wildcards:} Where does this pattern occur in the text if we ignore these characters?
        \item \textbf{Dictionary matching:} Where do any of these patterns occur in the text?
        \item \textbf{Parameterised matching:} Where does this pattern match the text if we relabel the pattern under some one-one mapping?
        \item \textbf{Distance matching:} How much does this text differ from the pattern?
    \end{itemize}

    From here, the topic broadens out even further, giving way to a wide variety of applications. Parameterised matching for example has seen a number of applications in checking for duplicated code \cite{Baker:1993:TPP:167088.167115} and plagiarism in software \cite{Pandey:plagiarism}, checking source files for where the same code is used with merely a few variables difference. Dictionary matching has seen applications in problems ranging from bioinformatics -- matching against whole databases of genomes \cite{15713233} -- to intrusion detection -- matching the contents of data packets against collections of attack patterns \cite{1354682} \cite{website:snort-algo}. $k$-mismatch solutions have also been used in bioinformatics for aligning sequences with a reference genome \cite{Tennakoon10062012}.

    But there is a problem here. For many of these applications, the size of the data is orders of magnitude greater than the original solutions were devised for. Take dictionary matching as an example, for which the applications mentioned above use an algorithm devised in 1975 by Aho and Corasick \cite{Aho:1975:ESM:360825.360855}. When Aho and Corasick first proposed this algorithm, they did not intend for it to be used to match databases of genomes or attack patterns. Instead, they used it to match two dozen keywords in the titles of various academic papers. Even more pressing is that they explicitly state in their paper that for some applications the algorithm may be unappealing because of its space consumption.

    It might be interesting to ask at this point if this can't simply be resolved by improvements in hardware. But there are a number of problems with this line of thinking. Firstly, even if we assume the space available on RAM will never stop increasing and that we can always use this space fully, the amount of data we want to process is still increasing faster than our capability to store it. As it was said by Lincoln Stein, ``at some time in the not too distant future it will cost less to sequence a base of DNA than to store it on a hard disk.'' \cite{20441614} And secondly, there are some cases where we do not want to keep adding RAM to our hardware as that will most likely increase the physical space of these devices. Examples of this include pattern matching on our phone, or on embedded systems such as intrusion detection on routers.

    Since 2009 \cite{5438620}, a number of solutions have been discovered to prove that it is possible to solve a number of problems not only in less space than it takes to store the text, but less space than it takes to even store the pattern. Following this, the aims of our work following this research proposal is to develop on these results further, focusing on two areas in particular:

    \begin{itemize}
        \item In the theory domain, we aim to improve upon current time and space bounds for the $k$-mismatch, parameterised matching and dictionary matching problems. We also seek to provide the first sublinear space solution for pattern matching with both multiple texts and multiple patterns.
        \item In the applied domain, we aim to provide implementations of both algorithms developed following the theoretical work in this research proposal and previous algorithms which to our knowledge have never seen prior implementation. We seek to test these algorithms and compare their performance to benchmark solutions in real applications, and improve the real world performance by finding and optimising practical bottlenecks. Finally, we aim to release these implementations as practical tools to the Open-Source community under the GNU General Public License (GPL).
    \end{itemize}

    \section{Background}

    It is straightforward to find a way of not needing to store the whole text on a machine. A lot of pattern matching algorithms such as Knuth-Morris-Pratt \cite{kmp} function by only reading one character of the text at a time. Thus we only need to store a window of the text in memory during processing, as opposed to the whole text, and update that window as we read the next character of the text. This is frequently known as \textit{streaming} the input, and is more formally called the time series model \cite{TCS-002}.

    But pattern matching in less space than it takes to store the pattern is significantly more difficult. Intuitively, this makes sense; how can we check if a pattern has occurred if we don't have enough space to know what the pattern is? Clifford et al.\@ \cite{clifford:black-box} proved that this intuition held for many problems; as long as we did not want any chance of errors, it was impossible to perform pattern matching in sublinear space relative to the pattern.

    But in 2009, Porat and Porat \cite{5438620} proved that the problem was in not allowing for errors. If we allowed a chance of both false positive and false negative results with some negligible probability of error, we could achieve a solution for the classic pattern matching problem in $O(n\log m)$ time and $O(\log m)$ space, where $n$ and $m$ are the length of the text and pattern respectively. This was the first ever solution to, as the authors themselves put it, break ``the $O(m)$ barrier that held for this problem for a long time.'' Breslauer and Galil \cite{Breslauer:2014:RSS:2660854.2635814} improved on this work even further, reducing the time complexity of the algorithm to constant time per character, or $O(n)$ time over the whole text.

    Subsequent work has been focused around two areas. The first, largely investigated by Clifford et al.\@ \cite{DBLP:journals/corr/abs-1106-4412}, provided a number of key insights into the space lower bounds of these problems. In particular, they proved that the classic pattern matching problem requires $\Omega(\log m)$ words of space, and many other problems including distance matching and pattern matching with wildcards as mentioned above require at least linear space.

    The second direction was to see what other problems could be solved in this area. Alongside their solution for classic pattern matching, Porat and Porat \cite{5438620} provided a solution to the $k$-mismatch problem in $O(k^2\polylog m)$ time and $O(k^3\polylog m)$ space. The next major breakthrough was in 2013, when Jalsenius, Porat and Sach \cite{JPS:2013} provided a solution to the parameterised matching problem in $O(|\Sigma|\log m)$ space, and introduced a lower bound of $\Omega(|\Sigma|)$ space, where $\Sigma$ is the alphabet of the text and pattern. The most recent accomplishment in this direction has been by Clifford et al.\@ \cite{2015arXiv150406242C}, which provided a solution to the dictionary matching problem of $O(k\log m)$ space and $O(\log\log(k + m))$ time per character, where $k$ is the number of patterns and $m$ is the longest pattern.

    For our theoretical contributions, we will aim to provide results in both directions. We will investigate the gaps in time complexity between the sublinear space solutions and the best-known results. Under dictionary matching for example, the best known time complexity is constant time per character by using Aho-Corasick, while Clifford et al.'s sublinear space solution uses $O(\log\log(k + m))$ time per character. We will also seek to reduce the gaps between known upper and lower bounds with regards to space complexity. $k$-mismatch for example has a known space lower bound in classical computing of $O(k\log k)$, yet no currently known solution hits this bound.

    In the practical world, work has been a lot less well-known. There are little to no currently published papers on implementing these algorithms, and thus we know almost nothing about how well these algorithms will perform in practice. This has been a common problem throughout theoretical computer science, and has thus resulted in a number of conferences based around applied and experimental work, such as Conference on Algorithms and Discrete Applied Mathematics (CALDAM)\footnote{\url{http://caldam.cse.iitk.ac.in/}} and the International Conference on Applied Algorithms (ICAA)\footnote{\url{https://sites.google.com/site/icaa2014/}}.

    To offer contributions to the practical domain, we will implement classic solutions to pattern matching algorithms as benchmarks and provide implementations of these more recent solutions. We will complement these implementations with a number of test benches for the problems, similar to the experimental setup of the Pizza\&Chili Corpus\footnote{\url{http://pizzachili.dcc.uchile.cl/index.html}} for text indexing. To ensure our work is reproduceable, we will host online access to these experimental setups and allow visitors the ability to contribute their own solutions to the pattern matching problems. Using these test benches will also give us key insights into the practical bottlenecks of these algorithms, and give us ideas as to how we can reduce the size of the constants that result from this work. Finally, we will release these solutions publicly under the GPL, and propose integration into projects such as Snort.

    \section{Objectives and deliverables}

    Our aims for this project are to investigate improvements to the current theoretical achievements stated above, propose new solutions to currently open problems, and develop practical implementations of these algorithms to release to the public. Specifically, our objectives are:

    \begin{enumerate}
        \item To work on improvements to current bounds for a number of problems, including time bounds for dictionary matching, space bounds for parameterised matching, and time and space bounds for $k$-mismatch.
        \item To propose solutions to open problems. In particular, the only currently known sublinear space solution for the problem of matching multiple patterns against multiple texts involves running multiple independent instances of the Clifford et al.\@ algorithm for dictionary matching.
        \item To develop implementations of algorithms from both this project and other work, and develop test benches in order to profile and optimise bottlenecks when running these algorithms on real data.
        \item To release these implementations to the open-source community under the GPL.
    \end{enumerate}

    \subsection{Deliverables}

    \begin{enumerate}
        \item New solutions to time and space bounds for current problems, through reducing upper bounds by improving the solutions and/or increasing lower bounds by novel methods.
        \item Publicly accessible test benches for analysis of various streaming solutions to different pattern matching problems.
        \item Release of source code as libraries under the GPL, and proposals for integration into other open source projects such as the Snort intrusion prevention system.
    \end{enumerate}

    \section{Work programme}

    \subsection*{WP1: Advances in theoretical work}

    Research leader: Dominic Moylett

    Principle research objective:
    \begin{quote}
        To reduce the current gaps between upper and lower bounds for sublinear space pattern matching algorithms through both improving the best known theoretical algorithms and exploring potential new methods for increasing lower bounds.
    \end{quote}

    Principle deliverables:
    \begin{enumerate}
        \item Stuff
    \end{enumerate}

    \subsection*{WP2: Implementation of theoretical work}

    Research leader: Charles Anderson

    Principle research objective:
    \begin{quote}
        Words
    \end{quote}

    Principle deliverables:
    \begin{enumerate}
        \item Stuff
    \end{enumerate}

    \subsection*{WP3: Release of open-source tools}

    Research leader: Dominic Moylett

    Principle research objective:
    \begin{quote}
        Words
    \end{quote}

    Principle deliverables:
    \begin{enumerate}
        \item Stuff
    \end{enumerate}

    \section{Academic Impact}

    \bibliography{research_proposal}

    \newpage
    \section{Budget}

    \newpage
    \section{Justification for resources}

    \newpage
    \section{Impact statement}

    \newpage
    \section{Workplan}

\end{document}
